{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Lab 04 for the course Machine Learning\n",
    "###### Student: Hristijan Stojchevski 161278"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from pylab import rcParams\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sb\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats\n",
    "import operator\n",
    "\n",
    "from sklearn.cluster import AgglomerativeClustering\n",
    "import sklearn.metrics as sm\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.feature_selection import SelectKBest, f_regression, mutual_info_regression\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.mixture import GaussianMixture\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.cluster import DBSCAN\n",
    "from sklearn.utils.multiclass import type_of_target\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold, RepeatedKFold, cross_val_score\n",
    "from sklearn.linear_model import LinearRegression, Lasso, ElasticNet, Ridge, BayesianRidge\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.neural_network import MLPClassifier, MLPRegressor\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.svm import SVC, SVR\n",
    "from sklearn.preprocessing import MinMaxScaler, LabelEncoder, StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "from scipy.cluster.hierarchy import dendrogram, linkage, fcluster, cophenet\n",
    "\n",
    "from collections import Counter\n",
    "import warnings\n",
    "scaler = MinMaxScaler()\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## REGRESSION PROBLEM\n",
    "\n",
    "### Forest fires dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "model_results = {}\n",
    "\n",
    "forest_data = pd.read_csv(\"../data/forest-fires/forestfires.csv\")\n",
    "print(forest_data)\n",
    "X = forest_data.iloc[:,:-1]\n",
    "X = X.to_numpy(dtype=np.object,copy=True, na_value=0)\n",
    "y = forest_data.iloc[:,-1]\n",
    "y = y.to_numpy(copy=True)\n",
    "months = np.unique(X[:,2])\n",
    "days = np.unique(X[:,3])\n",
    "X = X.T\n",
    "for i, c in zip(range(0, 12), months):\n",
    "    X[2, X[2] == c] = i\n",
    "for i, c in zip(range(0, 7), days):\n",
    "    X[3, X[3] == c] = i\n",
    "X = X.T\n",
    "X = scaler.fit_transform(X)\n",
    "print(X)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.25,random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Visualization\n",
    "- From the correlation matrix we can see that features 0,1,4,5,6,7,8 are highly corelated.\n",
    " But this is strange, because the correlation between month and temperature is low."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "correlation = forest_data.corr(method='pearson')\n",
    "columns = correlation.nlargest(10, 'area').index\n",
    "correlation_map = np.corrcoef(forest_data[columns].values.T)\n",
    "sb.set(font_scale=1.0)\n",
    "heatmap = sb.heatmap(correlation_map, cbar=True, annot=True, square=True, fmt='.2f', yticklabels=columns.values, xticklabels=columns.values)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "num_features = len(X[0])\n",
    "print(num_features)\n",
    "correlation_matrix = np.zeros((num_features,num_features))\n",
    "for i in range(num_features): #We need a 8x8 matrix to represent the correlation matrix, where we set the value of Cij to be the correlation between the i'th and the j'th metric\n",
    "    measure = X[:,i]\n",
    "    for j in range(num_features):\n",
    "        measure2 = X[:,j]\n",
    "        corr, _ = stats.pearsonr(measure, measure2)\n",
    "        correlation_matrix[i][j] = corr\n",
    "plt.figure()\n",
    "plt.imshow(correlation_matrix, cmap = \"inferno\") #We can draw the matrix using imshow\n",
    "plt.colorbar()\n",
    "plt.show()\n",
    "\n",
    "# Feature plot\n",
    "feature_names = forest_data.iloc[:,:-1].columns\n",
    "print(feature_names)\n",
    "fig = plt.figure(figsize=(12, 12))\n",
    "fig.subplots(num_features//2+1, ncols=2)\n",
    "fig.tight_layout(pad=6)\n",
    "for feat_i in range(num_features): #The histograms of the features\n",
    "    ax = plt.subplot(num_features//2+1,2, feat_i+1)\n",
    "    plt.title(feature_names[feat_i])\n",
    "    sb.distplot(X[:,feat_i], color = \"navy\")\n",
    "ax = plt.subplot(num_features//2+1,2, feat_i+2)\n",
    "plt.title(\"Target: area\")\n",
    "sb.distplot(y, color = \"darkorange\") #The histograms of the target variable\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "for feat_i in range(num_features):\n",
    "    plt.figure()\n",
    "    plt.scatter( X[:, feat_i], y,  alpha=.8, color=\"darkorange\")\n",
    "    plt.xticks(())\n",
    "    plt.yticks(())\n",
    "    ax.axis('equal')\n",
    "    plt.title(feature_names[feat_i] + \" x \" + forest_data.columns[-1])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "for feat_i in range(num_features):\n",
    "    sb.jointplot(X[:, feat_i], y, kind=\"kde\", space=0, color=\"g\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# feature selection\n",
    "def select_features(X_tr, y_tr, X_te, regressor=f_regression, keep='all'):\n",
    "\t# configure to select all features\n",
    "\tfs = SelectKBest(score_func=regressor, k=keep)\n",
    "\t# learn relationship from training data\n",
    "\tfs.fit(X_tr, y_tr)\n",
    "\t# transform train input data\n",
    "\tX_train_fs = fs.transform(X_tr)\n",
    "\t# transform test input data\n",
    "\tX_test_fs = fs.transform(X_te)\n",
    "\treturn X_train_fs, X_test_fs, fs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Feature selection and extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# X_train_fs2, X_test_fs2, fs2 = select_features(X_train,y_train, X_test, mutual_info_regression, 9)\n",
    "# for i in range(len(fs2.scores_)):\n",
    "# \tprint('Feature %d: %f' % (i, fs2.scores_[i]))\n",
    "# # plot the scores\n",
    "# plt.bar([i for i in range(len(fs2.scores_))], fs2.scores_)\n",
    "# plt.show()\n",
    "# print(len(X_train_fs2[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "reg_res = { 'MSE': 0, 'RMSE': 0, 'MAE': 0}\n",
    "# define the evaluation method\n",
    "cv = RepeatedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "# define the pipeline to evaluate\n",
    "model = LinearRegression()\n",
    "fs = SelectKBest(score_func=mutual_info_regression)\n",
    "pipeline = Pipeline(steps=[('sel',fs), ('lr', model)])\n",
    "# define the grid\n",
    "grid = dict()\n",
    "grid['sel__k'] = [i for i in range(2, 13)]\n",
    "# define the grid search\n",
    "search = GridSearchCV(pipeline, grid, scoring='neg_mean_squared_error', n_jobs=-1, cv=cv)\n",
    "# perform the search\n",
    "results = search.fit(X, y)\n",
    "# summarize best\n",
    "print('Best MAE: %.3f' % results.best_score_)\n",
    "print('Best Config: %s' % results.best_params_)\n",
    "# summarize all\n",
    "means = results.cv_results_['mean_test_score']\n",
    "params = results.cv_results_['params']\n",
    "for mean, param in zip(means, params):\n",
    "    print(\">%.3f with: %r\" % (mean, param))\n",
    "max_mean = results.best_score_\n",
    "num_keep = results.best_params_['sel__k']\n",
    "\n",
    "print(\"Means\", means)\n",
    "print(\"Params\", params)\n",
    "\n",
    "# define the pipeline to evaluate\n",
    "model = LinearRegression()\n",
    "fs = SelectKBest(score_func=f_regression)\n",
    "pipeline = Pipeline(steps=[('sel',fs), ('lr', model)])\n",
    "# define the grid\n",
    "grid = dict()\n",
    "grid['sel__k'] = [i for i in range(2, 13)]\n",
    "# define the grid search\n",
    "search = GridSearchCV(pipeline, grid, scoring='neg_mean_squared_error', n_jobs=-1, cv=cv)\n",
    "# perform the search\n",
    "results = search.fit(X, y)\n",
    "# summarize best\n",
    "print('Best MAE: %.3f' % results.best_score_)\n",
    "print('Best Config: %s' % results.best_params_)\n",
    "# summarize all\n",
    "for mean, param in zip(results.cv_results_['mean_test_score'], results.cv_results_['params']):\n",
    "    print(\">%.3f with: %r\" % (mean, param))\n",
    "if results.best_score_ > max_mean:\n",
    "    num_keep = results.best_params_['sel__k']\n",
    "    max_mean = results.best_score_\n",
    "    X_train_fs1, X_test_fs1, fs1 = select_features(X_train,y_train, X_test, f_regression, num_keep)\n",
    "    for i in range(len(fs1.scores_)):\n",
    "        print('Feature %d: %f' % (i, fs1.scores_[i]))\n",
    "    # plot the scores\n",
    "    plt.bar([i for i in range(len(fs1.scores_))], fs1.scores_)\n",
    "    plt.show()\n",
    "    print(len(X_train_fs1[0]))\n",
    "    model = LinearRegression()\n",
    "    model.fit(X_train_fs1, y_train)\n",
    "    # evaluate the model\n",
    "    y_pred = model.predict(X_test_fs1)\n",
    "    # evaluate predictions\n",
    "    mse = sm.mean_squared_error(y_test, y_pred)\n",
    "    rmse = np.sqrt(mse)\n",
    "    mae = sm.mean_absolute_error(y_test, y_pred)\n",
    "    print('MSE: %.3f' % mse)\n",
    "    print('RMSE: %.3f' % rmse)\n",
    "    print('MAE: %.3f' % mae)\n",
    "\n",
    "    reg_res['MSE'] = mse\n",
    "    reg_res['RMSE'] = rmse\n",
    "    reg_res['MAE'] = mae\n",
    "else:\n",
    "    X_train_fs1, X_test_fs1, fs1 = select_features(X_train,y_train, X_test, f_regression, num_keep)\n",
    "    for i in range(len(fs1.scores_)):\n",
    "        print('Feature %d: %f' % (i, fs1.scores_[i]))\n",
    "    # plot the scores\n",
    "    plt.bar([i for i in range(len(fs1.scores_))], fs1.scores_)\n",
    "    plt.show()\n",
    "    print(len(X_train_fs1[0]))\n",
    "    model = LinearRegression()\n",
    "    model.fit(X_train_fs1, y_train)\n",
    "    # evaluate the model\n",
    "    y_pred = model.predict(X_test_fs1)\n",
    "    # evaluate predictions\n",
    "    mse = sm.mean_squared_error(y_test, y_pred)\n",
    "    rmse = np.sqrt(mse)\n",
    "    mae = sm.mean_absolute_error(y_test, y_pred)\n",
    "    print('MSE: %.3f' % mse)\n",
    "    print('RMSE: %.3f' % rmse)\n",
    "    print('MAE: %.3f' % mae)\n",
    "\n",
    "    reg_res['MSE'] = mse\n",
    "    reg_res['RMSE'] = rmse\n",
    "    reg_res['MAE'] = mae\n",
    "\n",
    "custom_X_train = np.vstack((X_train.T[0:3], X_train.T[5:10], X_train.T[11]))\n",
    "custom_X_train = custom_X_train.T\n",
    "custom_X_test = np.vstack((X_test.T[0:3], X_test.T[5:10], X_test.T[11]))\n",
    "custom_X_test = custom_X_test.T\n",
    "model = LinearRegression()\n",
    "model.fit(custom_X_train, y_train)\n",
    "# evaluate the model\n",
    "y_pred = model.predict(custom_X_test)\n",
    "# evaluate predictions\n",
    "mse = sm.mean_squared_error(y_test, y_pred)\n",
    "rmse = np.sqrt(mse)\n",
    "mae = sm.mean_absolute_error(y_test, y_pred)\n",
    "print(\"Custom chosen parameters\")\n",
    "print('MSE: %.3f' % mse)\n",
    "print('RMSE: %.3f' % rmse)\n",
    "print('MAE: %.3f' % mae)\n",
    "\n",
    "if mse < reg_res['MSE']:\n",
    "    reg_res['MSE'] = mse\n",
    "    reg_res['RMSE'] = rmse\n",
    "    reg_res['MAE'] = mae\n",
    "\n",
    "model_results['LRE'] = reg_res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Pipelining multiple regression models to find the best one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "pipelines = []\n",
    "pipelines.append(('ScaledLR', Pipeline([('Scaler', StandardScaler()),('LR',LinearRegression())])))\n",
    "pipelines.append(('ScaledLASSO', Pipeline([('Scaler', StandardScaler()),('LASSO', Lasso())])))\n",
    "pipelines.append(('ScaledEN', Pipeline([('Scaler', StandardScaler()),('EN', ElasticNet())])))\n",
    "pipelines.append(('ScaledKNN', Pipeline([('Scaler', StandardScaler()),('KNN', KNeighborsRegressor())])))\n",
    "pipelines.append(('ScaledCART', Pipeline([('Scaler', StandardScaler()),('CART', DecisionTreeRegressor())])))\n",
    "pipelines.append(('ScaledGBM', Pipeline([('Scaler', StandardScaler()),('GBM', GradientBoostingRegressor())])))\n",
    "pipelines.append(('ScaledRIDGE', Pipeline([('Scaler', StandardScaler()),('RIDGE', Ridge())])))\n",
    "pipelines.append(('ScaledBAYESR', Pipeline([('Scaler', StandardScaler()),('BR', BayesianRidge())])))\n",
    "pipelines.append(('ScaledSVR', Pipeline([('Scaler', StandardScaler()),('SVR', SVR())])))\n",
    "pipelines.append(('ScaledNN', Pipeline([('Scaler', StandardScaler()),('NN', MLPRegressor())])))\n",
    "\n",
    "results = []\n",
    "names = []\n",
    "for name, model in pipelines:\n",
    "    kfold = RepeatedKFold(n_splits=10,n_repeats=3, random_state=21)\n",
    "    cv_results = cross_val_score(model, X_train, y_train, cv=kfold, scoring='neg_mean_squared_error')\n",
    "    results.append(cv_results)\n",
    "    names.append(name)\n",
    "    msg = \"%s: %f (%f)\" % (name, cv_results.mean(), cv_results.std())\n",
    "    print(msg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Od prethodnoto testiranje moze da zakluchime deka edni od podobrite modeli se BayesianRidge i nevronska mreza"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Set the parameters by cross-validation CV\n",
    "param_list = {\"hidden_layer_sizes\": [(9,),(50,),(100,0),(500,0),(1000,0),(4,2),(8,2),(20,2)],\n",
    "              \"activation\": [\"tanh\", \"relu\"],\n",
    "              \"solver\": [\"sgd\", \"adam\"],\n",
    "              \"alpha\": [0.0001, 0.00005,0.001, 0.005, 0.01, 0.05],\n",
    "              \"learning_rate_init\": [0.00001, 0.001, 0.01, 0.1]\n",
    "              }\n",
    "MLPRegressor()\n",
    "\n",
    "clf = GridSearchCV(MLPRegressor(), param_list, scoring='neg_mean_squared_error')\n",
    "clf.fit(X_train, y_train)\n",
    "print(\"Best parameters for forest fires NN are:\", clf.best_params_)\n",
    "print(\"Report for development parameters:\")\n",
    "means = clf.cv_results_['mean_test_score']\n",
    "stds = clf.cv_results_['std_test_score']\n",
    "for mean, std, params in zip(means, stds, clf.cv_results_['params']):\n",
    "    print(\"%0.3f (+/-%0.03f) for %r\"\n",
    "          % (mean, std * 2, params))\n",
    "y1_true, y1_pred = y_test, clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "mlp = MLPRegressor(hidden_layer_sizes=(9,), activation='tanh', solver='sgd', alpha=0.0001, learning_rate_init=0.01)\n",
    "mlp.fit(X_train,y_train)\n",
    "y_pred = mlp.predict(X_test)\n",
    "mse = sm.mean_squared_error(y_test, y_pred)\n",
    "rmse = np.sqrt(mse)\n",
    "mae = sm.mean_absolute_error(y_test, y_pred)\n",
    "print(\"MLPRegressor score:\")\n",
    "print('MSE: %.3f' % mse)\n",
    "print('RMSE: %.3f' % rmse)\n",
    "print('MAE: %.3f' % mae)\n",
    "reg_res['MSE'] = mse\n",
    "reg_res['RMSE'] = rmse\n",
    "reg_res['MAE'] = mae\n",
    "model_results['MLPReg'] = reg_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Set the parameters by cross-validation CV\n",
    "param_list = {\"n_iter\": [50, 100, 300, 500],\n",
    "              \"normalize\": [False, True]\n",
    "              }\n",
    "\n",
    "# letters 1\n",
    "clf_let = GridSearchCV(BayesianRidge(), param_list, scoring='neg_mean_squared_error')\n",
    "clf_let.fit(X_train, y_train)\n",
    "print(\"Best parameters for forest fires NN are:\", clf_let.best_params_)\n",
    "print(\"Report for development parameters:\")\n",
    "means = clf_let.cv_results_['mean_test_score']\n",
    "stds = clf_let.cv_results_['std_test_score']\n",
    "for mean, std, params in zip(means, stds, clf_let.cv_results_['params']):\n",
    "    print(\"%0.3f (+/-%0.03f) for %r\"\n",
    "          % (mean, std * 2, params))\n",
    "y1_true, y1_pred = y_test, clf_let.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "bRidge = BayesianRidge(n_iter=100)\n",
    "bRidge.fit(X_train, y_train)\n",
    "y_pred = bRidge.predict(X_test)\n",
    "mse = sm.mean_squared_error(y_test, y_pred)\n",
    "rmse = np.sqrt(mse)\n",
    "mae = sm.mean_absolute_error(y_test, y_pred)\n",
    "print(\"Bayesian Ridge score:\")\n",
    "print('MSE: %.3f' % mse)\n",
    "print('RMSE: %.3f' % rmse)\n",
    "print('MAE: %.3f' % mae)\n",
    "reg_res['MSE'] = mse\n",
    "reg_res['RMSE'] = rmse\n",
    "reg_res['MAE'] = mae\n",
    "model_results['MLPReg'] = reg_res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "##### Best model is the one with the lowest MSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "best_model = {}\n",
    "min_mse = 1000\n",
    "for name, scores in model_results.items():\n",
    "    if min_mse > scores['MSE']:\n",
    "        min_mse = scores['MSE']\n",
    "        best_model = model_results[name]\n",
    "        best_model['name'] = name\n",
    "print(best_model['name'], \"is the best model for predicting this dataset and the scores are:\")\n",
    "print(\"MSE:\", best_model['MSE'])\n",
    "print(\"RMSE\", best_model['RMSE'])\n",
    "print(\"MAE\", best_model['MAE'])\n",
    "best_model = min(model_results.items(), key=operator.itemgetter(1).itemgetter(1))\n",
    "print(best_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Letter recognition dataset\n",
    "\n",
    "## Letter recognition data proccesing and no need for extra Normalization, the dataset was already Normalized to integer values 0-15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "dataLettersFull = np.loadtxt(open('../Datasets/letter-recognition.data'),delimiter=',',dtype=np.object)\n",
    "dataLetters = dataLettersFull[:,1:].astype(np.int)\n",
    "dataLetters_class = dataLettersFull[:,0].astype(np.str)\n",
    "let_train, let_test, letY_train, letY_test = train_test_split(dataLetters,dataLetters_class, test_size=0.3333, random_state=42)\n",
    "print(len(let_test))\n",
    "\n",
    "target = dataLetters_class.copy()\n",
    "unique_class = np.unique(target)\n",
    "target = target.astype(np.object)\n",
    "for i, c in zip(range(0,len(unique_class)), unique_class):\n",
    "    target[target == c] = i\n",
    "print(target)\n",
    "pca_3D = PCA(n_components=3)\n",
    "pca_3D.fit(dataLetters[:2500])\n",
    "pca_t3 = pca_3D.fit_transform(dataLetters[:2500])\n",
    "pca_t3 = np.ascontiguousarray(pca_t3)\n",
    "\n",
    "\n",
    "fig = plt.figure(figsize=(12,10))\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "ax.scatter(pca_t3[:,0],pca_t3[:,1],pca_t3[:,2],c=target[:2500])\n",
    "ax.set_xlabel('PCA_1')\n",
    "ax.set_ylabel(\"PCA_2\")\n",
    "ax.set_zlabel(\"PCA_3\")\n",
    "print(pca_t3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification on letter dataset\n",
    "- Data is seperated into 1/3 for validation and 2/3 for training the models\n",
    "- From the results below we can see that the best NN model is the one with 700 neurons in the hidden layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "letters_MLP1 = MLPClassifier((6,),learning_rate_init=0.01)\n",
    "letters_MLP2 = MLPClassifier((100,),learning_rate_init=0.01)\n",
    "letters_MLP3 = MLPClassifier((700,),learning_rate_init=0.01)\n",
    "letters_MLP4 = MLPClassifier((2,2),learning_rate_init=0.01)\n",
    "letters_MLP5 = MLPClassifier((4,2),learning_rate_init=0.01)\n",
    "# 50 in hidden LR = 0.01, test size = 0.5*N\n",
    "letters_MLP1.fit(let_train,letY_train)\n",
    "predictions_let = letters_MLP1.predict(let_test)\n",
    "N = len(dataLetters)\n",
    "n_test = len(let_test)\n",
    "acc = 0\n",
    "for pred, ver in zip(predictions_let, letY_test):\n",
    "    if pred == ver:\n",
    "       acc += 1\n",
    "print(\"Acurr of letters dataset NN1 is :\",acc/n_test)\n",
    "letters_MLP2.fit(let_train,letY_train)\n",
    "predictions_let = letters_MLP2.predict(let_test)\n",
    "N = len(dataLetters)\n",
    "n_test = len(let_test)\n",
    "acc = 0\n",
    "for pred, ver in zip(predictions_let, letY_test):\n",
    "    if pred == ver:\n",
    "       acc += 1\n",
    "print(\"Acurr of letters dataset NN2 is :\",acc/n_test)\n",
    "letters_MLP3.fit(let_train,letY_train)\n",
    "# predictions_let = letters_MLP3.predict(let_test)\n",
    "# N = len(dataLetters)//\n",
    "n_test = len(let_test)\n",
    "acc = 0\n",
    "for pred, ver in zip(predictions_let, letY_test):\n",
    "    if pred == ver:\n",
    "       acc += 1\n",
    "print(\"Acurr of letters dataset NN3 is :\",acc/n_test)\n",
    "letters_MLP4.fit(let_train,letY_train)\n",
    "predictions_let = letters_MLP4.predict(let_test)\n",
    "N = len(dataLetters)\n",
    "n_test = len(let_test)\n",
    "acc = 0\n",
    "for pred, ver in zip(predictions_let, letY_test):\n",
    "    if pred == ver:\n",
    "       acc += 1\n",
    "print(\"Acurr of letters dataset NN4 is :\",acc/n_test)\n",
    "letters_MLP5.fit(let_train,letY_train)\n",
    "predictions_let = letters_MLP5.predict(let_test)\n",
    "N = len(dataLetters)\n",
    "n_test = len(let_test)\n",
    "acc = 0\n",
    "for pred, ver in zip(predictions_let, letY_test):\n",
    "    if pred == ver:\n",
    "       acc += 1\n",
    "print(\"Acurr of letters dataset NN5 is :\",acc/n_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVM For Letters\n",
    "\n",
    "- As the best SVM model is choosen the one with gaussian kernel and parameters C = 1000 and gamma = 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Set the parameters by cross-validation CV\n",
    "tuned_parameters = [{'kernel': ['linear'], 'C': [1, 10, 100, 1000]},\n",
    "                    {'kernel': ['rbf'], 'gamma': [0.001,1e-3, 1e-4],'C': [1, 10, 100, 1000]}]\n",
    "# letters 1\n",
    "clf_let = GridSearchCV(SVC(), tuned_parameters, scoring='precision_macro') #  5-fold CV on 2/3 of data\n",
    "clf_let.fit(let_train, letY_train)\n",
    "print(\"Best parameters for letters:\", clf_let.best_params_)\n",
    "print(\"Report for development parameters:\")\n",
    "means = clf_let.cv_results_['mean_test_score']\n",
    "stds = clf_let.cv_results_['std_test_score']\n",
    "for mean, std, params in zip(means, stds, clf_let.cv_results_['params']):\n",
    "    print(\"%0.3f (+/-%0.03f) for %r\"\n",
    "          % (mean, std * 2, params))\n",
    "y1_true, y1_pred = letY_test, clf_let.predict(let_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVM report\n",
    "\n",
    "### The best SVM model has proven to be 96% precise which makes the best model for this datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "    Tuka imame rezultati od test klasifikacijata so 1/3 od data\n",
    "    So precision pokazuvame br na True Positives za sekoja od klasite nasproti vk broj na pozitivni tp / (tp + fp)\n",
    "\"\"\"\n",
    "print(\"Classification report for letters:\")\n",
    "print(classification_report(y1_true, y1_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
